{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\t욕설 감지 데이터셋\n",
    "\n",
    "데이터\n",
    "- 일간베스트(일베), 오늘의 유머와 같은 각종 커뮤니티 사이트의 댓글에 대해 총 5,825문장을 분류했습니다.\n",
    "- 수직선 기호( | )를 기준으로 좌측에는 댓글 내용, 우측에는 욕설 여부(0,1)가 기록되어 있습니다.\n",
    "- '존맛', '개이득' 등의 말은 비속어를 포함하고 있으므로 욕설이라 볼 수 있으나 최근에는 강조의 의미로 흔히 쓰이고 있으므로 악의가 없는 단순 강조의 의미로 쓰였다고 판단될 경우 욕설로 분류하지 않았습니다.\n",
    "- 상황에 따라 욕일 수도 있고, 아닐 수도 있는 댓글은 최대한 비욕설로 구분했습니다.\n",
    "- 출처 : https://github.com/2runo/Curse-detection-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Curse-detection-data'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/2runo/Curse-detection-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.228061Z",
     "start_time": "2021-04-23T05:55:21.476065Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "contents = []\n",
    "\n",
    "with open('Curse-detection-data/dataset.txt', 'r',encoding='UTF8') as f:\n",
    "    reader = csv.reader(f, delimiter = '\\t')\n",
    "    for row in f:\n",
    "        contents.append(row.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.272935Z",
     "start_time": "2021-04-23T05:55:22.229055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임</td>\n",
       "      <td>0\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...</td>\n",
       "      <td>1\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>너가 한 말 중에</td>\n",
       "      <td>0\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>제갈대중 ㅇㅂ</td>\n",
       "      <td>0\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>우리나라교회는 악마들이모여 주뎅이 처벌리고</td>\n",
       "      <td>1\\n</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5825 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document label  none\n",
       "0                                             좌배 까는건 ㅇㅂ   1\\n  None\n",
       "1                          집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ   0\\n  None\n",
       "2           개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아   1\\n  None\n",
       "3                                           세탁이라고 봐도 된다   0\\n  None\n",
       "4                                    애새끼가 초딩도 아니고 ㅋㅋㅋㅋ    1\\n  None\n",
       "...                                                 ...   ...   ...\n",
       "5820         좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임   0\\n  None\n",
       "5821  세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...   1\\n  None\n",
       "5822                                          너가 한 말 중에   0\\n  None\n",
       "5823                                            제갈대중 ㅇㅂ   0\\n  None\n",
       "5824                           우리나라교회는 악마들이모여 주뎅이 처벌리고    1\\n  None\n",
       "\n",
       "[5825 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(contents, columns=['document','label','none'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label 값 \\n 처리 , none 열 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.287897Z",
     "start_time": "2021-04-23T05:55:22.274930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>여자 형제 둔 남성 보수 성향 강해… 美조사</td>\n",
       "      <td>한경닷컴 - 한국경제여자 형제가 인생을 더 행복하게 만든다 - 동아일보여자 형제 ...</td>\n",
       "      <td>0\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      document  \\\n",
       "455  여자 형제 둔 남성 보수 성향 강해… 美조사    \n",
       "\n",
       "                                                 label none  \n",
       "455   한경닷컴 - 한국경제여자 형제가 인생을 더 행복하게 만든다 - 동아일보여자 형제 ...  0\\n  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'].apply(lambda x: '한경' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.302855Z",
     "start_time": "2021-04-23T05:55:22.289891Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(455, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.317817Z",
     "start_time": "2021-04-23T05:55:22.304850Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x : int(x.replace(\"\\n\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.422536Z",
     "start_time": "2021-04-23T05:55:22.417549Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('none',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:22.602056Z",
     "start_time": "2021-04-23T05:55:22.591086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3780\n",
       "1    2044\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고 : https://wikidocs.net/94748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.737224Z",
     "start_time": "2021-04-23T05:55:22.920206Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.752177Z",
     "start_time": "2021-04-23T05:55:28.739210Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5824, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['document'].nunique(),df['label'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.767135Z",
     "start_time": "2021-04-23T05:55:28.756166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.782095Z",
     "start_time": "2021-04-23T05:55:28.769130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰의 개수 : 4368\n",
      "테스트용 리뷰의 개수 : 1456\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df, test_size = 0.25, random_state = 42)\n",
    "print('훈련용 리뷰의 개수 :', len(train_data))\n",
    "print('테스트용 리뷰의 개수 :', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.946657Z",
     "start_time": "2021-04-23T05:55:28.784092Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3ee0cba00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰화\n",
    "\n",
    "1. Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불용어 제거 \n",
    "- stopwords 생성\n",
    "- 갖고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 큰 의미가 없는 단어 토큰을 제거하는 작업 필요\n",
    "- 큰 의미가 없다라는 것은 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:28.961616Z",
     "start_time": "2021-04-23T05:55:28.947654Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.410546Z",
     "start_time": "2021-04-23T05:55:28.963611Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-ff1de90eb13d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['tokenized'] = train_data['document'].apply(mecab.morphs)\n",
      "<ipython-input-14-ff1de90eb13d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
      "<ipython-input-14-ff1de90eb13d>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['tokenized'] = test_data['document'].apply(mecab.morphs)\n",
      "<ipython-input-14-ff1de90eb13d>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n"
     ]
    }
   ],
   "source": [
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "\n",
    "train_data['tokenized'] = train_data['document'].apply(mecab.morphs)\n",
    "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test_data['tokenized'] = test_data['document'].apply(mecab.morphs)\n",
    "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어와 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.455499Z",
     "start_time": "2021-04-23T05:55:29.417456Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
    "negative_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.485412Z",
     "start_time": "2021-04-23T05:55:29.457488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ㅋㅋㅋ', 818), ('.', 660), ('?', 354), ('거', 342), ('ㅋㅋ', 316), ('새끼', 274), ('있', 236), ('아', 188), ('안', 180), ('냐', 175), ('나', 170), ('보', 165), ('니', 147), ('어', 146), ('존나', 142), ('없', 142), ('같', 140), ('는데', 139), ('말', 136), ('일', 135)]\n"
     ]
    }
   ],
   "source": [
    "negative_word_count = Counter(negative_words)\n",
    "print(negative_word_count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.515332Z",
     "start_time": "2021-04-23T05:55:29.486410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 1052), ('?', 576), ('ㅋㅋㅋ', 364), ('있', 343), ('거', 333), ('ㅋㅋ', 294), ('냐', 242), ('안', 223), ('없', 218), ('나', 216), ('는데', 199), (',', 172), ('에서', 164), ('말', 160), ('으로', 158), ('아', 155), ('아니', 153), ('로', 152), ('보', 148), ('..', 145)]\n"
     ]
    }
   ],
   "source": [
    "positive_word_count = Counter(positive_words)\n",
    "print(positive_word_count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.799579Z",
     "start_time": "2021-04-23T05:55:29.517329Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정 리뷰의 평균 길이 : 18.443129520052597\n",
      "긍정 리뷰의 평균 길이 : 10.814892869687391\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "text_len = train_data[train_data['label']==1]['tokenized'].map(lambda x: len(x))\n",
    "ax1.hist(text_len, color='red')\n",
    "ax1.set_title('negative Reviews')\n",
    "ax1.set_xlabel('length of samples')\n",
    "ax1.set_ylabel('number of samples')\n",
    "print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n",
    "\n",
    "text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n",
    "ax2.hist(text_len, color='blue')\n",
    "ax2.set_title('positive Reviews')\n",
    "fig.suptitle('Words in texts')\n",
    "ax2.set_xlabel('length of samples')\n",
    "ax2.set_ylabel('number of samples')\n",
    "print('긍정 리뷰의 평균 길이 :', np.mean(text_len))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.814555Z",
     "start_time": "2021-04-23T05:55:29.800570Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_data['tokenized'].values\n",
    "y_train = train_data['label'].values\n",
    "X_test= test_data['tokenized'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.874396Z",
     "start_time": "2021-04-23T05:55:29.816550Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.919300Z",
     "start_time": "2021-04-23T05:55:29.875395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('안', 403),\n",
       "             ('그래도', 28),\n",
       "             ('요즘', 35),\n",
       "             ('숙박업', 1),\n",
       "             ('울상', 1),\n",
       "             ('일텐데', 1),\n",
       "             ('.', 1712),\n",
       "             ('.....', 4),\n",
       "             ('33', 1),\n",
       "             ('오', 69),\n",
       "             ('모이', 3),\n",
       "             ('말', 296),\n",
       "             ('시', 77),\n",
       "             ('키', 20),\n",
       "             ('아', 343),\n",
       "             ('그냥', 131),\n",
       "             ('홀딩', 1),\n",
       "             ('세요', 24),\n",
       "             ('빙신', 4),\n",
       "             ('!', 146),\n",
       "             ('!!!!!', 4),\n",
       "             ('저', 138),\n",
       "             ('꾸', 5),\n",
       "             ('피지컬', 1),\n",
       "             ('한국어', 1),\n",
       "             ('좀', 107),\n",
       "             ('배워서', 6),\n",
       "             ('김치', 19),\n",
       "             ('처먹', 17),\n",
       "             ('어도', 36),\n",
       "             ('월', 24),\n",
       "             ('10', 36),\n",
       "             ('억', 37),\n",
       "             ('간단', 2),\n",
       "             ('땡기', 2),\n",
       "             ('는데', 338),\n",
       "             ('왜', 122),\n",
       "             ('힘들', 20),\n",
       "             ('몸', 18),\n",
       "             ('파', 9),\n",
       "             ('냐', 417),\n",
       "             ('이기', 43),\n",
       "             ('야', 212),\n",
       "             ('정신', 31),\n",
       "             ('피폐', 2),\n",
       "             ('해', 213),\n",
       "             (',', 305),\n",
       "             ('돈', 157),\n",
       "             ('나눠', 3),\n",
       "             ('줘야', 8),\n",
       "             ('애', 113),\n",
       "             ('까지', 92),\n",
       "             ('낳', 8),\n",
       "             ('으면', 122),\n",
       "             ('어쩔', 8),\n",
       "             ('예', 20),\n",
       "             ('조선', 34),\n",
       "             ('-', 50),\n",
       "             ('100', 13),\n",
       "             ('->', 2),\n",
       "             ('일제', 4),\n",
       "             ('50', 20),\n",
       "             ('라는', 78),\n",
       "             ('거', 675),\n",
       "             ('둘', 25),\n",
       "             ('지금', 90),\n",
       "             ('처럼', 37),\n",
       "             ('완전히', 3),\n",
       "             ('자유', 10),\n",
       "             ('롭', 5),\n",
       "             ('못', 177),\n",
       "             ('해서', 109),\n",
       "             ('마이너스', 3),\n",
       "             ('지만', 81),\n",
       "             ('어찌', 9),\n",
       "             ('됐', 15),\n",
       "             ('건', 122),\n",
       "             ('보단', 8),\n",
       "             ('나았', 2),\n",
       "             ('다는', 67),\n",
       "             ('것', 184),\n",
       "             ('시발', 59),\n",
       "             ('존나', 151),\n",
       "             ('잘', 169),\n",
       "             ('함', 155),\n",
       "             ('많이', 60),\n",
       "             ('들어가', 21),\n",
       "             ('병', 23),\n",
       "             ('나', 386),\n",
       "             ('큰', 21),\n",
       "             ('의료비', 1),\n",
       "             ('나가', 28),\n",
       "             ('닉', 6),\n",
       "             ('값', 9),\n",
       "             ('ㅍㅌㅊ', 1),\n",
       "             ('좋', 156),\n",
       "             ('겠', 199),\n",
       "             ('저런', 58),\n",
       "             ('시장', 20),\n",
       "             ('가진', 8),\n",
       "             ('대구', 23),\n",
       "             ('~', 103),\n",
       "             ('선거', 12),\n",
       "             ('밥', 19),\n",
       "             ('사', 119),\n",
       "             ('먹', 131),\n",
       "             ('으라고', 6),\n",
       "             ('준다', 5),\n",
       "             ('잔', 4),\n",
       "             ('전라도', 22),\n",
       "             ('홍어', 47),\n",
       "             ('년놈', 5),\n",
       "             ('주', 173),\n",
       "             ('사양', 1),\n",
       "             ('가장', 10),\n",
       "             ('전하', 3),\n",
       "             ('공익', 2),\n",
       "             ('신고', 11),\n",
       "             ('제출', 6),\n",
       "             ('사항', 3),\n",
       "             ('으로', 292),\n",
       "             ('1', 94),\n",
       "             ('신고자', 1),\n",
       "             ('성명', 1),\n",
       "             ('연락처', 1),\n",
       "             ('2', 80),\n",
       "             ('위반', 5),\n",
       "             ('일시', 2),\n",
       "             ('장소', 2),\n",
       "             ('차량', 4),\n",
       "             ('번호', 5),\n",
       "             ('3', 54),\n",
       "             ('교통위반', 1),\n",
       "             ('증거', 6),\n",
       "             ('영상', 13),\n",
       "             ('또는', 2),\n",
       "             ('사진', 29),\n",
       "             ('이게', 35),\n",
       "             ('나라', 97),\n",
       "             ('?', 930),\n",
       "             ('공', 14),\n",
       "             ('수처', 3),\n",
       "             ('통과', 4),\n",
       "             ('될', 39),\n",
       "             ('알', 124),\n",
       "             ('있', 579),\n",
       "             ('었', 151),\n",
       "             ('마당', 2),\n",
       "             ('대체', 11),\n",
       "             ('어딜', 4),\n",
       "             ('봐서', 9),\n",
       "             ('파멸', 1),\n",
       "             ('보이', 31),\n",
       "             ('노', 231),\n",
       "             ('미국', 48),\n",
       "             ('년', 193),\n",
       "             ('인지', 33),\n",
       "             ('일본', 106),\n",
       "             ('수', 158),\n",
       "             ('없', 360),\n",
       "             ('인민', 2),\n",
       "             ('감시', 2),\n",
       "             ('시스템', 6),\n",
       "             ('구축', 3),\n",
       "             ('위해서', 7),\n",
       "             ('안면', 1),\n",
       "             ('인식', 14),\n",
       "             ('기술', 29),\n",
       "             ('데이터', 3),\n",
       "             ('로', 285),\n",
       "             ('쓰', 64),\n",
       "             ('려고', 24),\n",
       "             ('중국', 52),\n",
       "             ('공산당', 2),\n",
       "             ('그림', 1),\n",
       "             ('그린', 1),\n",
       "             ('영화', 17),\n",
       "             ('비', 15),\n",
       "             ('가족', 14),\n",
       "             ('기생충', 5),\n",
       "             ('조커', 3),\n",
       "             ('화두', 1),\n",
       "             ('빈부', 2),\n",
       "             ('격차', 2),\n",
       "             ('이유', 26),\n",
       "             ('세상', 30),\n",
       "             ('젊은이', 5),\n",
       "             ('시달리', 1),\n",
       "             ('기', 179),\n",
       "             ('때문', 45),\n",
       "             ('글', 116),\n",
       "             ('팩', 28),\n",
       "             ('트', 28),\n",
       "             ('조지', 3),\n",
       "             ('경기', 11),\n",
       "             ('아서', 57),\n",
       "             ('취직', 7),\n",
       "             ('된다고', 8),\n",
       "             ('아니', 271),\n",
       "             ('일', 252),\n",
       "             ('할', 183),\n",
       "             ('(', 35),\n",
       "             ('해도', 49),\n",
       "             ('일자리', 5),\n",
       "             ('질', 46),\n",
       "             ('적', 163),\n",
       "             ('부분', 14),\n",
       "             ('떨어짐', 2),\n",
       "             (')', 41),\n",
       "             ('그만큼', 3),\n",
       "             ('노인', 8),\n",
       "             ('인구', 12),\n",
       "             ('상당', 4),\n",
       "             ('골치', 1),\n",
       "             ('덩', 1),\n",
       "             ('명', 41),\n",
       "             ('당', 30),\n",
       "             ('근데', 92),\n",
       "             ('무슨', 37),\n",
       "             ('사토리', 1),\n",
       "             ('세대', 2),\n",
       "             ('행복', 8),\n",
       "             ('이건', 20),\n",
       "             ('반', 17),\n",
       "             ('대로', 26),\n",
       "             ('우리', 58),\n",
       "             ('한테', 94),\n",
       "             ('반면', 1),\n",
       "             ('교사', 5),\n",
       "             ('앞', 26),\n",
       "             ('2030', 1),\n",
       "             ('2040', 1),\n",
       "             ('보다', 80),\n",
       "             ('할테', 1),\n",
       "             ('거기', 30),\n",
       "             ('대한', 13),\n",
       "             ('복지', 9),\n",
       "             ('비용', 4),\n",
       "             ('생각', 136),\n",
       "             ('앞날', 1),\n",
       "             ('깜깜', 1),\n",
       "             ('그때', 12),\n",
       "             ('줄어들', 1),\n",
       "             ('테', 11),\n",
       "             ('현', 6),\n",
       "             ('초딩', 4),\n",
       "             ('20', 34),\n",
       "             ('대', 111),\n",
       "             ('30', 22),\n",
       "             ('별', 12),\n",
       "             ('하자', 1),\n",
       "             ('바로', 31),\n",
       "             ('다만', 7),\n",
       "             ('참고', 9),\n",
       "             ('해야', 63),\n",
       "             ('한다', 56),\n",
       "             ('일본인', 3),\n",
       "             ('과연', 3),\n",
       "             ('어떤', 19),\n",
       "             ('..', 219),\n",
       "             ('디플레', 1),\n",
       "             ('고통', 5),\n",
       "             ('받', 106),\n",
       "             ('아베', 5),\n",
       "             ('엔', 26),\n",
       "             ('정책', 3),\n",
       "             ('마치', 5),\n",
       "             ('실상', 4),\n",
       "             ('부채', 2),\n",
       "             ('내', 181),\n",
       "             ('불만', 1),\n",
       "             ('여론', 10),\n",
       "             ('잠식', 2),\n",
       "             ('시키', 21),\n",
       "             ('한국', 79),\n",
       "             ('이나', 92),\n",
       "             ('특히', 9),\n",
       "             ('뉴스', 11),\n",
       "             ('매일', 11),\n",
       "             ('시간', 31),\n",
       "             ('때우', 2),\n",
       "             ('예전', 15),\n",
       "             ('에서', 290),\n",
       "             ('보', 313),\n",
       "             ('던', 70),\n",
       "             ('모습', 7),\n",
       "             ('일까', 6),\n",
       "             (';;;', 5),\n",
       "             ('현실', 23),\n",
       "             ('직시', 1),\n",
       "             ('했', 182),\n",
       "             ('맞', 108),\n",
       "             ('인데', 111),\n",
       "             ('백수', 3),\n",
       "             ('천지', 3),\n",
       "             ('구나', 19),\n",
       "             ('제주도', 1),\n",
       "             ('까스', 2),\n",
       "             ('으러', 5),\n",
       "             ('간다고', 2),\n",
       "             ('부모', 16),\n",
       "             ('한숨', 1),\n",
       "             ('나오', 50),\n",
       "             ('아직', 30),\n",
       "             ('방독면', 1),\n",
       "             ('앉', 19),\n",
       "             ('쏴', 2),\n",
       "             ('옆', 17),\n",
       "             ('후임', 2),\n",
       "             ('표적', 2),\n",
       "             ('맞춰', 5),\n",
       "             ('넘겼', 2),\n",
       "             ('때', 147),\n",
       "             ('중대', 6),\n",
       "             ('간부', 5),\n",
       "             ('님', 62),\n",
       "             ('잊', 4),\n",
       "             ('못하', 27),\n",
       "             ('그', 155),\n",
       "             ('짜릿', 1),\n",
       "             ('정자', 2),\n",
       "             ('제공', 4),\n",
       "             ('자', 111),\n",
       "             ('누군데', 4),\n",
       "             ('그리고', 45),\n",
       "             ('46', 2),\n",
       "             ('세', 15),\n",
       "             ('임신', 3),\n",
       "             ('출산', 4),\n",
       "             ('가능', 61),\n",
       "             (';;', 11),\n",
       "             ('ㄷ', 135),\n",
       "             ('/', 71),\n",
       "             ('쥬얼', 1),\n",
       "             ('정도', 81),\n",
       "             ('데리', 4),\n",
       "             ('살', 125),\n",
       "             (';', 8),\n",
       "             ('김제동', 3),\n",
       "             ('분야', 6),\n",
       "             ('최고', 10),\n",
       "             ('권위자', 1),\n",
       "             ('아닌가', 16),\n",
       "             ('ㅋㅋㅋ', 1182),\n",
       "             ('자기', 41),\n",
       "             ('밥줄', 2),\n",
       "             ('니', 232),\n",
       "             ('공부', 63),\n",
       "             ('모든', 19),\n",
       "             ('기본', 7),\n",
       "             ('다를', 6),\n",
       "             ('이해', 35),\n",
       "             ('사람', 156),\n",
       "             ('누구', 19),\n",
       "             ('전제', 1),\n",
       "             ('얘기', 21),\n",
       "             ('필요', 21),\n",
       "             ('없이', 25),\n",
       "             ('뭐', 139),\n",
       "             ('어쩌', 16),\n",
       "             ('라고', 164),\n",
       "             ('하찮', 4),\n",
       "             ('축생', 2),\n",
       "             ('줄', 67),\n",
       "             ('감성', 3),\n",
       "             ('따위', 5),\n",
       "             ('타', 37),\n",
       "             ('서', 182),\n",
       "             ('훈수', 2),\n",
       "             ('이거', 41),\n",
       "             ('잖', 9),\n",
       "             ('이따위', 1),\n",
       "             ('유튜브', 11),\n",
       "             ('홍보', 5),\n",
       "             ('싶', 67),\n",
       "             ('놈', 90),\n",
       "             ('댓글', 32),\n",
       "             ('하나', 54),\n",
       "             ('이렇게', 27),\n",
       "             ('일일이', 2),\n",
       "             ('캡쳐', 7),\n",
       "             ('올리', 23),\n",
       "             ('광고', 8),\n",
       "             ('려는', 13),\n",
       "             ('아닌', 24),\n",
       "             ('이상', 54),\n",
       "             ('리뷰', 4),\n",
       "             ('관리', 8),\n",
       "             ('꼼꼼', 1),\n",
       "             ('곳', 42),\n",
       "             ('더라', 85),\n",
       "             ('좆', 93),\n",
       "             ('꼴리', 9),\n",
       "             ('무법천지', 1),\n",
       "             ('씨', 45),\n",
       "             ('성씨', 2),\n",
       "             ('유부', 1),\n",
       "             ('우동', 2),\n",
       "             ('달', 38),\n",
       "             ('창악', 1),\n",
       "             ('플', 9),\n",
       "             ('러', 31),\n",
       "             ('연령', 2),\n",
       "             ('딱', 58),\n",
       "             ('40', 13),\n",
       "             ('그래서', 36),\n",
       "             ('그걸', 23),\n",
       "             ('다고', 112),\n",
       "             ('법', 20),\n",
       "             ('처벌', 6),\n",
       "             ('않', 105),\n",
       "             ('지요', 8),\n",
       "             ('남', 79),\n",
       "             ('신경', 9),\n",
       "             ('쓸', 16),\n",
       "             ('4', 33),\n",
       "             ('5', 45),\n",
       "             ('원', 61),\n",
       "             ('내고', 1),\n",
       "             ('좌석', 2),\n",
       "             ('두', 41),\n",
       "             ('개', 150),\n",
       "             ('전부', 14),\n",
       "             ('버려라', 2),\n",
       "             ('이런', 78),\n",
       "             ('환경', 5),\n",
       "             ('랑', 80),\n",
       "             ('비슷', 21),\n",
       "             ('위치', 6),\n",
       "             ('특징', 10),\n",
       "             ('동쪽', 1),\n",
       "             ('부터', 70),\n",
       "             ('개발', 8),\n",
       "             ('편서풍', 2),\n",
       "             ('부니', 1),\n",
       "             ('까', 35),\n",
       "             ('...', 53),\n",
       "             ('란', 29),\n",
       "             ('결국', 16),\n",
       "             ('공장', 14),\n",
       "             ('짓', 39),\n",
       "             ('건데', 28),\n",
       "             ('지으면', 3),\n",
       "             ('전기', 6),\n",
       "             ('대량', 2),\n",
       "             ('발전소', 1),\n",
       "             ('어야제', 1),\n",
       "             ('원자력', 2),\n",
       "             ('현재', 6),\n",
       "             ('문', 28),\n",
       "             ('씹', 71),\n",
       "             ('쌔', 6),\n",
       "             ('같', 254),\n",
       "             ('머저리', 1),\n",
       "             ('새끼', 279),\n",
       "             ('대통령', 14),\n",
       "             ('과거', 12),\n",
       "             ('그런', 66),\n",
       "             ('어딨', 6),\n",
       "             ('무적', 5),\n",
       "             ('권', 38),\n",
       "             ('화력', 2),\n",
       "             ('매연', 1),\n",
       "             ('오지', 12),\n",
       "             ('미세먼지', 1),\n",
       "             ('부', 23),\n",
       "             ('서쪽', 1),\n",
       "             ('??', 24),\n",
       "             ('자살', 20),\n",
       "             ('단', 18),\n",
       "             ('소리', 45),\n",
       "             ('소문', 3),\n",
       "             ('으니', 25),\n",
       "             ('뿐', 21),\n",
       "             ('이하', 6),\n",
       "             ('습니다', 28),\n",
       "             ('베', 87),\n",
       "             ('댓', 6),\n",
       "             ('장문', 1),\n",
       "             ('ㅋㅋ', 610),\n",
       "             ('동물', 6),\n",
       "             ('직감', 2),\n",
       "             ('용접', 67),\n",
       "             ('잖아', 32),\n",
       "             ('꿀', 10),\n",
       "             ('직장', 9),\n",
       "             ('해로운', 1),\n",
       "             ('노동', 2),\n",
       "             ('직', 7),\n",
       "             ('굳이', 10),\n",
       "             ('한자', 2),\n",
       "             ('섞', 1),\n",
       "             ('어서', 88),\n",
       "             ('머', 23),\n",
       "             ('조선족', 12),\n",
       "             ('칼', 18),\n",
       "             ('찌르', 4),\n",
       "             ('시켜', 19),\n",
       "             ('집', 74),\n",
       "             ('팔', 32),\n",
       "             ('그걸로', 4),\n",
       "             ('놀', 10),\n",
       "             ('다가', 58),\n",
       "             ('일손', 1),\n",
       "             ('부족', 5),\n",
       "             ('부서', 3),\n",
       "             ('공무원', 19),\n",
       "             ('채용', 1),\n",
       "             ('문제', 38),\n",
       "             ('천', 31),\n",
       "             ('한텐', 1),\n",
       "             ('무지', 2),\n",
       "             ('인갑', 2),\n",
       "             ('구글', 6),\n",
       "             ('죽여야', 2),\n",
       "             ('살인', 2),\n",
       "             ('뎅이', 1),\n",
       "             ('병균', 1),\n",
       "             ('쳐', 42),\n",
       "             ('넣', 23),\n",
       "             ('돌아다니', 4),\n",
       "             ('세균전', 1),\n",
       "             ('라', 190),\n",
       "             ('든다', 4),\n",
       "             ('자정', 2),\n",
       "             ('작용', 2),\n",
       "             ('보람', 2),\n",
       "             ('튜브', 2),\n",
       "             ('봤', 48),\n",
       "             ('만족', 4),\n",
       "             ('퀄리티', 2),\n",
       "             ('더', 116),\n",
       "             ('줘서', 5),\n",
       "             ('뽑', 14),\n",
       "             ('걱정하지마', 2),\n",
       "             ('급', 23),\n",
       "             ('편집자', 2),\n",
       "             ('써도', 3),\n",
       "             ('난이도', 2),\n",
       "             ('컨텐츠', 5),\n",
       "             ('거나', 32),\n",
       "             ('사업', 8),\n",
       "             ('충분히', 5),\n",
       "             ('가용', 1),\n",
       "             ('범위', 1),\n",
       "             ('니까', 79),\n",
       "             ('운영', 9),\n",
       "             ('미쳤', 4),\n",
       "             ('진짜', 138),\n",
       "             ('ㅁ', 94),\n",
       "             ('ㅈ', 162),\n",
       "             ('ㅎ', 114),\n",
       "             ('방생', 3),\n",
       "             ('마', 46),\n",
       "             ('링크', 54),\n",
       "             ('번', 74),\n",
       "             ('은혜', 6),\n",
       "             ('복음', 4),\n",
       "             ('기록', 7),\n",
       "             ('성경', 2),\n",
       "             ('로마서', 2),\n",
       "             ('빌레몬서', 1),\n",
       "             ('이외', 1),\n",
       "             ('쓰여진', 1),\n",
       "             ('명령', 4),\n",
       "             ('교회', 11),\n",
       "             ('시대', 23),\n",
       "             ('지켜야', 1),\n",
       "             ('구절', 3),\n",
       "             ('암튼', 8),\n",
       "             ('미련', 3),\n",
       "             ('다면', 16),\n",
       "             ('너', 80),\n",
       "             ('와이프', 6),\n",
       "             ('중', 70),\n",
       "             ('어학연수', 1),\n",
       "             ('라도', 48),\n",
       "             ('면서', 106),\n",
       "             ('직접', 7),\n",
       "             ('경험', 5),\n",
       "             ('길', 50),\n",
       "             ('추천', 14),\n",
       "             ('중고', 7),\n",
       "             ('신입', 1),\n",
       "             ('경우', 23),\n",
       "             ('34', 1),\n",
       "             ('35', 3),\n",
       "             ('겐', 2),\n",
       "             ('뻬이', 1),\n",
       "             ('만세', 7),\n",
       "             ('새벽', 5),\n",
       "             ('고소장', 1),\n",
       "             ('어디', 50),\n",
       "             ('씨발', 75),\n",
       "             ('무섭', 7),\n",
       "             ('유관순', 1),\n",
       "             ('열사', 1),\n",
       "             ('ㅠㅠ', 22),\n",
       "             ('mechanism', 1),\n",
       "             ('스트레스', 8),\n",
       "             ('취하', 2),\n",
       "             ('마시', 7),\n",
       "             ('술', 16),\n",
       "             ('빡', 18),\n",
       "             ('대가', 2),\n",
       "             ('리야', 1),\n",
       "             ('헌', 2),\n",
       "             ('법조문', 1),\n",
       "             ('다시', 28),\n",
       "             ('상기', 1),\n",
       "             ('파보', 1),\n",
       "             ('막', 20),\n",
       "             ('비례', 6),\n",
       "             ('출신', 20),\n",
       "             ('마스크', 10),\n",
       "             ('장점', 1),\n",
       "             ('빨', 50),\n",
       "             ('땀', 2),\n",
       "             ('훨씬', 15),\n",
       "             ('덜', 7),\n",
       "             ('차', 59),\n",
       "             ('외피', 2),\n",
       "             ('알콜', 1),\n",
       "             ('소독', 3),\n",
       "             ('점', 20),\n",
       "             ('비싸', 13),\n",
       "             ('어', 287),\n",
       "             ('쩌', 2),\n",
       "             ('투덜대', 1),\n",
       "             ('너도나도', 1),\n",
       "             ('재끼', 1),\n",
       "             ('죠', 27),\n",
       "             ('결혼', 37),\n",
       "             ('지원금', 2),\n",
       "             ('짜리', 9),\n",
       "             ('하다못해', 1),\n",
       "             ('저게', 14),\n",
       "             ('식', 14),\n",
       "             ('약', 6),\n",
       "             ('처', 15),\n",
       "             ('공식', 4),\n",
       "             ('마스코트', 1),\n",
       "             ('된', 62),\n",
       "             ('일회용', 1),\n",
       "             ('홍보물', 1),\n",
       "             ('대놓', 2),\n",
       "             ('도라에몽', 3),\n",
       "             ('쓰인', 1),\n",
       "             ('그게', 37),\n",
       "             ('상품화', 1),\n",
       "             ('주장', 7),\n",
       "             ('병신', 121),\n",
       "             ('잼', 13),\n",
       "             ('블', 8),\n",
       "             ('박', 17),\n",
       "             ('=', 37),\n",
       "             ('본인', 20),\n",
       "             ('블루', 1),\n",
       "             ('컬러', 2),\n",
       "             ('직업', 38),\n",
       "             ('이러', 12),\n",
       "             ('ㅉㅉ', 23),\n",
       "             ('프랑스', 4),\n",
       "             ('모두', 11),\n",
       "             ('셧다운', 1),\n",
       "             ('봄', 20),\n",
       "             ('너무', 49),\n",
       "             ('오버', 2),\n",
       "             ('냐고', 15),\n",
       "             (':', 34),\n",
       "             ('깜', 8),\n",
       "             ('방', 6),\n",
       "             ('처음', 14),\n",
       "             ('바', 22),\n",
       "             ('pe', 1),\n",
       "             ('석사', 1),\n",
       "             ('한다고', 29),\n",
       "             ('몇', 54),\n",
       "             ('나중', 16),\n",
       "             ('북한', 17),\n",
       "             ('여자', 80),\n",
       "             ('야겠다', 2),\n",
       "             ('이쁜', 6),\n",
       "             ('골라서', 2),\n",
       "             ('육', 3),\n",
       "             ('변기', 2),\n",
       "             ('풀', 14),\n",
       "             ('갇', 1),\n",
       "             ('데', 87),\n",
       "             ('노무', 8),\n",
       "             ('유명', 7),\n",
       "             ('곱창', 5),\n",
       "             ('손질', 1),\n",
       "             ('인건비', 1),\n",
       "             ('70', 12),\n",
       "             ('%', 45),\n",
       "             ('됨', 55),\n",
       "             ('제대로', 22),\n",
       "             ('손', 21),\n",
       "             ('이랑', 50),\n",
       "             ('숙성', 1),\n",
       "             ('삼', 14),\n",
       "             ('걸린다', 1),\n",
       "             ('ㅇ줄', 1),\n",
       "             ('아이구', 1),\n",
       "             ('얘', 15),\n",
       "             ('며칠', 2),\n",
       "             ('전', 65),\n",
       "             ('히', 3),\n",
       "             ('심', 7),\n",
       "             ('여유', 1),\n",
       "             ('그나마', 8),\n",
       "             ('정확', 3),\n",
       "             ('해석', 9),\n",
       "             ('해줄께', 1),\n",
       "             ('는군요', 4),\n",
       "             ('해요', 2),\n",
       "             ('지원', 7),\n",
       "             ('끼리', 21),\n",
       "             ('나눈', 1),\n",
       "             ('상류층', 1),\n",
       "             ('개보', 6),\n",
       "             ('지랑', 2),\n",
       "             ('하층민', 3),\n",
       "             ('처녀', 3),\n",
       "             ('비견', 2),\n",
       "             ('자체', 33),\n",
       "             ('가치', 13),\n",
       "             ('매우', 1),\n",
       "             ('크', 13),\n",
       "             ('방증', 2),\n",
       "             ('제발', 25),\n",
       "             ('잡', 57),\n",
       "             ('가두', 1),\n",
       "             ('~~', 32),\n",
       "             ('뚜', 3),\n",
       "             ('렛', 4),\n",
       "             ('이후', 15),\n",
       "             ('믿', 29),\n",
       "             ('쯤', 7),\n",
       "             ('남대', 1),\n",
       "             ('전북', 1),\n",
       "             ('상황', 22),\n",
       "             ('궁금', 6),\n",
       "             ('지네', 6),\n",
       "             ('최대', 4),\n",
       "             ('수준', 29),\n",
       "             ('최소', 10),\n",
       "             ('은데', 49),\n",
       "             ('콩밥', 1),\n",
       "             ('자지', 4),\n",
       "             ('썰', 7),\n",
       "             ('어야', 19),\n",
       "             ('횡보', 1),\n",
       "             ('9', 18),\n",
       "             ('후', 19),\n",
       "             ('여파', 1),\n",
       "             ('갈', 22),\n",
       "             ('사실', 35),\n",
       "             ('쓸데없이', 1),\n",
       "             ('켜', 3),\n",
       "             ('강력', 2),\n",
       "             ('유감', 1),\n",
       "             ('뜻', 9),\n",
       "             ('표한다', 1),\n",
       "             ('쪽', 27),\n",
       "             ('바리', 6),\n",
       "             ('만화', 6),\n",
       "             ('느라', 2),\n",
       "             ('애썼', 2),\n",
       "             ('나베', 8),\n",
       "             ('지도자', 4),\n",
       "             ('서울', 19),\n",
       "             ('7', 39),\n",
       "             ('불', 24),\n",
       "             ('체자', 2),\n",
       "             ('불법', 9),\n",
       "             ('입국', 6),\n",
       "             ('등등', 18),\n",
       "             ('많', 103),\n",
       "             ('밖', 18),\n",
       "             ('ㅇ', 44),\n",
       "             ('ㅔ없음', 1),\n",
       "             ('바닷가', 1),\n",
       "             ('가깝', 3),\n",
       "             ('집값', 5),\n",
       "             ('쌈', 3),\n",
       "             ('속해', 1),\n",
       "             ('상', 23),\n",
       "             ('인천', 1),\n",
       "             ('경기도', 2),\n",
       "             ('가까운', 3),\n",
       "             ('동네', 28),\n",
       "             ('그러', 35),\n",
       "             ('불체', 1),\n",
       "             ('외노', 9),\n",
       "             ('짱', 17),\n",
       "             ('온갖', 3),\n",
       "             ('인간', 42),\n",
       "             ('들락날락', 1),\n",
       "             ('첫', 9),\n",
       "             ('스타트', 2),\n",
       "             ('끊어졌', 1),\n",
       "             ('예지', 8),\n",
       "             ('걸레', 9),\n",
       "             ('함부로', 3),\n",
       "             ('아라', 8),\n",
       "             ('앜', 2),\n",
       "             ('비록', 2),\n",
       "             ('을지', 4),\n",
       "             ('모르', 53),\n",
       "             ('목표', 5),\n",
       "             ('잃', 2),\n",
       "             ('는다면', 1),\n",
       "             ('영웅본색', 1),\n",
       "             ('라서', 19),\n",
       "             ('뭘', 26),\n",
       "             ('본데', 1),\n",
       "             ('머리', 32),\n",
       "             ('여군', 2),\n",
       "             ('빡빡이', 1),\n",
       "             ('군인', 4),\n",
       "             ('간', 20),\n",
       "             ('세상만사', 1),\n",
       "             ('복잡', 1),\n",
       "             ('쌩까', 2),\n",
       "             ('절대', 19),\n",
       "             ('연락', 7),\n",
       "             ('먼저', 10),\n",
       "             ('올', 7),\n",
       "             ('욕', 35),\n",
       "             ('꿈틀대', 1),\n",
       "             ('쥬', 6),\n",
       "             ('거지', 11),\n",
       "             ('논하', 1),\n",
       "             ('자칭', 4),\n",
       "             ('미래', 5),\n",
       "             ('꽤', 7),\n",
       "             ('봐', 21),\n",
       "             ('얼마나', 17),\n",
       "             ('는지', 35),\n",
       "             ('인증', 13),\n",
       "             ('ㄱ', 26),\n",
       "             ('지옥', 7),\n",
       "             ('자식', 13),\n",
       "             ('가정', 4),\n",
       "             ('교육', 9),\n",
       "             ('시킨', 9),\n",
       "             ('뒤진', 8),\n",
       "             ('증조할아버지', 1),\n",
       "             ('시작', 17),\n",
       "             ('싸그리', 1),\n",
       "             ('모가지', 1),\n",
       "             ('잘라', 1),\n",
       "             ('버린다', 2),\n",
       "             ('서비스', 8),\n",
       "             ('애미', 20),\n",
       "             ('변기통', 1),\n",
       "             ('쳐넣', 1),\n",
       "             ('밟', 4),\n",
       "             ('목', 4),\n",
       "             ('꺾', 5),\n",
       "             ('죽여', 7),\n",
       "             ('드림', 1),\n",
       "             ('k', 9),\n",
       "             ('흑', 4),\n",
       "             ('열', 14),\n",
       "             ('전차', 2),\n",
       "             ('실제로', 8),\n",
       "             ('위압감', 1),\n",
       "             ('자주포', 1),\n",
       "             ('ㅆㅅㅌㅊ', 8),\n",
       "             ('밀', 8),\n",
       "             ('덕', 10),\n",
       "             ('씩', 18),\n",
       "             ('히로뽕', 2),\n",
       "             ('다경', 1),\n",
       "             ('교대', 5),\n",
       "             ('뽕', 18),\n",
       "             ('쟁이', 4),\n",
       "             ('재소자', 1),\n",
       "             ('의무실', 1),\n",
       "             ('계호', 1),\n",
       "             ('보고', 9),\n",
       "             ('단순', 4),\n",
       "             ('기분', 11),\n",
       "             ('목적', 6),\n",
       "             ('ㅅ', 74),\n",
       "             ('라던', 3),\n",
       "             ('데비', 1),\n",
       "             ('아그라', 1),\n",
       "             ('효과', 4),\n",
       "             ('단다', 2),\n",
       "             ('좌', 15),\n",
       "             ('만선', 3),\n",
       "             ('에요', 2),\n",
       "             ('누나', 7),\n",
       "             ('즤', 1),\n",
       "             ('겅', 1),\n",
       "             ('들어도', 1),\n",
       "             ('피', 13),\n",
       "             ('거꾸로', 1),\n",
       "             ('솟', 1),\n",
       "             ('는다', 17),\n",
       "             ('평화', 1),\n",
       "             ('소린데', 1),\n",
       "             ('미친', 35),\n",
       "             ('빠', 25),\n",
       "             ('고려', 3),\n",
       "             ('괜찮', 17),\n",
       "             ('중세', 4),\n",
       "             ('였', 63),\n",
       "             ('태종', 1),\n",
       "             ('편', 14),\n",
       "             ('국', 35),\n",
       "             ('물', 35),\n",
       "             ('세종', 2),\n",
       "             ('망조', 1),\n",
       "             ('양반', 5),\n",
       "             ('귀족', 1),\n",
       "             ('에게', 35),\n",
       "             ('성군', 1),\n",
       "             ('몰라도', 5),\n",
       "             ('당시', 5),\n",
       "             ('쳐도', 4),\n",
       "             ('500', 7),\n",
       "             ('후퇴', 1),\n",
       "             ('개막', 2),\n",
       "             ('장', 22),\n",
       "             ('한글', 1),\n",
       "             ('원래', 24),\n",
       "             ('독음', 1),\n",
       "             ('표기법', 1),\n",
       "             ('몽', 4),\n",
       "             ('아예', 5),\n",
       "             ('짱깨', 24),\n",
       "             ('노예', 15),\n",
       "             ('국가', 25),\n",
       "             ('전락', 3),\n",
       "             ('장본인', 1),\n",
       "             ('며', 26),\n",
       "             ('백성', 1),\n",
       "             ('노비', 6),\n",
       "             ('만들', 40),\n",
       "             ('한반도', 2),\n",
       "             ('근대', 1),\n",
       "             ('화', 26),\n",
       "             ('초석', 1),\n",
       "             ('틀어막', 1),\n",
       "             ('재앙', 17),\n",
       "             ('천하', 1),\n",
       "             ('개새끼', 21),\n",
       "             ('조건', 9),\n",
       "             ('죄', 12),\n",
       "             ('형벌', 1),\n",
       "             ('깨달', 2),\n",
       "             ('ㄴ', 58),\n",
       "             ('외모', 12),\n",
       "             ('다음', 34),\n",
       "             ('날', 29),\n",
       "             ('아침', 6),\n",
       "             ('놀란', 1),\n",
       "             ('기억', 10),\n",
       "             ('부탁', 4),\n",
       "             ('가만히', 6),\n",
       "             ('ㅡㅡ', 8),\n",
       "             ('총선', 7),\n",
       "             ('뮨', 2),\n",
       "             ('재인', 2),\n",
       "             ('독재', 10),\n",
       "             ('으려면', 2),\n",
       "             ('황', 2),\n",
       "             ('해야함', 3),\n",
       "             ('방향', 4),\n",
       "             ('뻔히', 1),\n",
       "             ('못함', 11),\n",
       "             ('티', 8),\n",
       "             ('케이', 2),\n",
       "             ('퍼', 19),\n",
       "             ('물갈이', 1),\n",
       "             ('과반', 1),\n",
       "             ('넘', 33),\n",
       "             ('민주당', 13),\n",
       "             ('자리', 16),\n",
       "             ('잇', 14),\n",
       "             ('우김', 1),\n",
       "             ('불출마', 3),\n",
       "             ('이미', 23),\n",
       "             ('오래', 7),\n",
       "             ('김무성', 6),\n",
       "             ('욕함', 6),\n",
       "             ('진', 28),\n",
       "             ('도배', 2),\n",
       "             ('ㅇㅇ', 33),\n",
       "             ('연애', 4),\n",
       "             ('할땐', 3),\n",
       "             ('았', 91),\n",
       "             ('???', 7),\n",
       "             ('하하하하하하', 2),\n",
       "             ('휴', 5),\n",
       "             ...])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.934237Z",
     "start_time": "2021-04-23T05:55:29.920299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10434\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 5995\n",
      "단어 집합에서 희귀 단어의 비율: 57.45639256277554\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 10.188300873525712\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:29.949197Z",
     "start_time": "2021-04-23T05:55:29.936244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4441\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:30.083837Z",
     "start_time": "2021-04-23T05:55:29.952188Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:32.564507Z",
     "start_time": "2021-04-23T05:55:32.269298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 384\n",
      "리뷰의 평균 길이 : 13.471153846153847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:35.935815Z",
     "start_time": "2021-04-23T05:55:35.929832Z"
    }
   },
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:37.349694Z",
     "start_time": "2021-04-23T05:55:37.336727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 300 이하인 샘플의 비율: 99.93131868131869\n"
     ]
    }
   ],
   "source": [
    "max_len = 300\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:38.188937Z",
     "start_time": "2021-04-23T05:55:38.135081Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:39.027695Z",
     "start_time": "2021-04-23T05:55:39.008746Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:40.375440Z",
     "start_time": "2021-04-23T05:55:40.358486Z"
    }
   },
   "outputs": [],
   "source": [
    "def DNN():\n",
    "    # 모델 구조 정의하기\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(layers.Dense(128, activation='relu')) \n",
    "    model.add(layers.Dense(128, activation='relu')) #ReLU 활성화함수 채택\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('DNN',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:40.719695Z",
     "start_time": "2021-04-23T05:55:40.708550Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('LSTM',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:41.588401Z",
     "start_time": "2021-04-23T05:55:41.577430Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_2_layer():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(LSTM(128, return_sequences=True,activation='relu'))\n",
    "    model.add(LSTM(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('LSTM_2layer',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:42.172838Z",
     "start_time": "2021-04-23T05:55:42.159908Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Bidirectional(LSTM(128,activation='relu')))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('Bi-LSTM',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:44.351292Z",
     "start_time": "2021-04-23T05:55:44.342316Z"
    }
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm_2():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True,activation='relu')))\n",
    "    model.add(Bidirectional(LSTM(128,activation='relu')))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('Bi-LSTM-2',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:55:45.207032Z",
     "start_time": "2021-04-23T05:55:45.189052Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "def cnn_1D():\n",
    "    model = Sequential()    \n",
    "    model.add(Embedding(vocab_size, 100,input_length = max_len))\n",
    "    model.add(Conv1D(256, 3, padding='valid', activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, callbacks=[es, mc], batch_size=32, validation_split=0.2)\n",
    "    loaded_model = load_model('best_model.h5')\n",
    "    score = loaded_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"테스트 정확도: %.4f\" % (score))\n",
    "    test_result.append(('1D-CNN',score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T03:04:37.086232Z",
     "start_time": "2021-04-23T02:14:46.690774Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.6523 - acc: 0.6454\n",
      "Epoch 00001: val_acc improved from -inf to 0.67206, saving model to best_model.h5\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6523 - acc: 0.6454 - val_loss: 0.6319 - val_acc: 0.6721\n",
      "Epoch 2/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.6513\n",
      "Epoch 00002: val_acc improved from 0.67206 to 0.67209, saving model to best_model.h5\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6472 - acc: 0.6513 - val_loss: 0.6343 - val_acc: 0.6721\n",
      "Epoch 3/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.6523\n",
      "Epoch 00003: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 0.6463 - acc: 0.6521 - val_loss: 0.6367 - val_acc: 0.6720\n",
      "Epoch 4/30\n",
      "108/110 [============================>.] - ETA: 0s - loss: 0.6454 - acc: 0.6526\n",
      "Epoch 00004: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.6456 - acc: 0.6523 - val_loss: 0.6326 - val_acc: 0.6720\n",
      "Epoch 5/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6454 - acc: 0.6519\n",
      "Epoch 00005: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.6452 - acc: 0.6522 - val_loss: 0.6331 - val_acc: 0.6719\n",
      "Epoch 6/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.6521\n",
      "Epoch 00006: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6449 - acc: 0.6524 - val_loss: 0.6374 - val_acc: 0.6720\n",
      "Epoch 7/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6446 - acc: 0.6527\n",
      "Epoch 00007: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.6447 - acc: 0.6525 - val_loss: 0.6346 - val_acc: 0.6719\n",
      "Epoch 8/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6450 - acc: 0.6526\n",
      "Epoch 00008: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 0.6450 - acc: 0.6526 - val_loss: 0.6361 - val_acc: 0.6719\n",
      "Epoch 9/30\n",
      "108/110 [============================>.] - ETA: 0s - loss: 0.6436 - acc: 0.6522\n",
      "Epoch 00009: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.6434 - acc: 0.6526 - val_loss: 0.6352 - val_acc: 0.6719\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.6448 - acc: 0.6525\n",
      "Epoch 00010: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 0.6448 - acc: 0.6525 - val_loss: 0.6354 - val_acc: 0.6719\n",
      "Epoch 11/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.6443 - acc: 0.6526- ETA: 0s - loss: 0.\n",
      "Epoch 00011: val_acc did not improve from 0.67209\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.6443 - acc: 0.6526 - val_loss: 0.6383 - val_acc: 0.6720\n",
      "Epoch 00011: early stopping\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6513 - acc: 0.6426\n",
      "테스트 정확도: 0.6426\n",
      "\n",
      "LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.5889 - acc: 0.6926\n",
      "Epoch 00001: val_acc improved from -inf to 0.77002, saving model to best_model.h5\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.5889 - acc: 0.6926 - val_loss: 0.5049 - val_acc: 0.7700\n",
      "Epoch 2/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8718\n",
      "Epoch 00002: val_acc improved from 0.77002 to 0.82609, saving model to best_model.h5\n",
      "110/110 [==============================] - 36s 327ms/step - loss: 0.3251 - acc: 0.8718 - val_loss: 0.4410 - val_acc: 0.8261\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.1729 - acc: 0.9385\n",
      "Epoch 00003: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 37s 338ms/step - loss: 0.1729 - acc: 0.9385 - val_loss: 0.4993 - val_acc: 0.7895\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.9677\n",
      "Epoch 00004: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 36s 331ms/step - loss: 0.1013 - acc: 0.9677 - val_loss: 0.7224 - val_acc: 0.7849\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.1101 - acc: 0.9588\n",
      "Epoch 00005: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 37s 334ms/step - loss: 0.1101 - acc: 0.9588 - val_loss: 0.5688 - val_acc: 0.7243\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.1686 - acc: 0.9385\n",
      "Epoch 00006: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 31s 281ms/step - loss: 0.1686 - acc: 0.9385 - val_loss: 0.5946 - val_acc: 0.7975\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.9820\n",
      "Epoch 00007: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 34s 311ms/step - loss: 0.0609 - acc: 0.9820 - val_loss: 0.7551 - val_acc: 0.8009\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0432 - acc: 0.9888\n",
      "Epoch 00008: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 37s 340ms/step - loss: 0.0432 - acc: 0.9888 - val_loss: 0.8786 - val_acc: 0.7494\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0434 - acc: 0.9894\n",
      "Epoch 00009: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 39s 356ms/step - loss: 0.0434 - acc: 0.9894 - val_loss: 0.8075 - val_acc: 0.7689\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9877\n",
      "Epoch 00010: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 38s 343ms/step - loss: 0.0384 - acc: 0.9877 - val_loss: 0.9336 - val_acc: 0.7689\n",
      "Epoch 11/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9926\n",
      "Epoch 00011: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 33s 300ms/step - loss: 0.0271 - acc: 0.9926 - val_loss: 1.0058 - val_acc: 0.7517\n",
      "Epoch 12/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0223 - acc: 0.9937\n",
      "Epoch 00012: val_acc did not improve from 0.82609\n",
      "110/110 [==============================] - 32s 289ms/step - loss: 0.0223 - acc: 0.9937 - val_loss: 1.1103 - val_acc: 0.7494\n",
      "Epoch 00012: early stopping\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 0.4541 - acc: 0.8297\n",
      "테스트 정확도: 0.8297\n",
      "\n",
      "LSTM_2layer 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6620\n",
      "Epoch 00001: val_acc improved from -inf to 0.67048, saving model to best_model.h5\n",
      "110/110 [==============================] - 67s 613ms/step - loss: nan - acc: 0.6620 - val_loss: nan - val_acc: 0.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlagy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1664: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00002: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 61s 558ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00003: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 73s 662ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00004: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 67s 607ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00005: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 69s 631ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00006: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 67s 607ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00007: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 69s 627ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00008: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 69s 623ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00009: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 66s 598ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00010: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 65s 589ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 00010: early stopping\n",
      "46/46 [==============================] - 9s 201ms/step - loss: nan - acc: 0.6408\n",
      "테스트 정확도: 0.6408\n",
      "\n",
      "Bi-LSTM 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6460\n",
      "Epoch 00001: val_acc improved from -inf to 0.67048, saving model to best_model.h5\n",
      "110/110 [==============================] - 55s 496ms/step - loss: nan - acc: 0.6460 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 2/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00002: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 53s 480ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00003: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 51s 468ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00004: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 52s 477ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00005: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 53s 482ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00006: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 48s 440ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00007: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 47s 423ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00008: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 43s 393ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00009: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 49s 449ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00010: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 47s 430ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 00010: early stopping\n",
      "46/46 [==============================] - 4s 76ms/step - loss: nan - acc: 0.6408\n",
      "테스트 정확도: 0.6408\n",
      "\n",
      "Bi-LSTM 2층 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6494\n",
      "Epoch 00001: val_acc improved from -inf to 0.67048, saving model to best_model.h5\n",
      "110/110 [==============================] - 136s 1s/step - loss: nan - acc: 0.6494 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 2/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00002: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 139s 1s/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00003: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 141s 1s/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00004: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 119s 1s/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00005: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 108s 977ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00006: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 108s 983ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00007: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 112s 1s/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00008: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 108s 984ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00009: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 107s 970ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: nan - acc: 0.6471\n",
      "Epoch 00010: val_acc did not improve from 0.67048\n",
      "110/110 [==============================] - 109s 992ms/step - loss: nan - acc: 0.6471 - val_loss: nan - val_acc: 0.6705\n",
      "Epoch 00010: early stopping\n",
      "46/46 [==============================] - 11s 230ms/step - loss: nan - acc: 0.6408\n",
      "테스트 정확도: 0.6408\n",
      "\u0001D-CNN 모델 진행합니다.\n",
      "Epoch 1/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6915\n",
      "Epoch 00001: val_acc improved from -inf to 0.81236, saving model to best_model.h5\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5973 - acc: 0.6915 - val_loss: 0.4370 - val_acc: 0.8124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8678\n",
      "Epoch 00002: val_acc improved from 0.81236 to 0.85126, saving model to best_model.h5\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.3262 - acc: 0.8681 - val_loss: 0.3788 - val_acc: 0.8513\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.9499\n",
      "Epoch 00003: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.1543 - acc: 0.9499 - val_loss: 0.4883 - val_acc: 0.8364\n",
      "Epoch 4/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9762\n",
      "Epoch 00004: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 0.0788 - acc: 0.9762 - val_loss: 0.5977 - val_acc: 0.8169\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0348 - acc: 0.9908\n",
      "Epoch 00005: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.0348 - acc: 0.9908 - val_loss: 0.7332 - val_acc: 0.8032\n",
      "Epoch 6/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9966\n",
      "Epoch 00006: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.0183 - acc: 0.9966 - val_loss: 0.8482 - val_acc: 0.8101\n",
      "Epoch 7/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9966\n",
      "Epoch 00007: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.8918 - val_acc: 0.7895\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0107 - acc: 0.9977\n",
      "Epoch 00008: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.0107 - acc: 0.9977 - val_loss: 0.9656 - val_acc: 0.8055\n",
      "Epoch 9/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9974\n",
      "Epoch 00009: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 1.0254 - val_acc: 0.7872\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0091 - acc: 0.9983- ETA: 0s - loss: 0.0094 - acc: 0.9\n",
      "Epoch 00010: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 1.0550 - val_acc: 0.7872\n",
      "Epoch 11/30\n",
      "109/110 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 00011: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 1.0968 - val_acc: 0.8055\n",
      "Epoch 12/30\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 00012: val_acc did not improve from 0.85126\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 1.1782 - val_acc: 0.7986\n",
      "Epoch 00012: early stopping\n",
      "46/46 [==============================] - 0s 10ms/step - loss: 0.3969 - acc: 0.8434\n",
      "테스트 정확도: 0.8434\n"
     ]
    }
   ],
   "source": [
    "test_result = []    \n",
    "print(\"\\nDNN 모델 진행합니다.\")\n",
    "DNN()\n",
    "print(\"\\nLSTM 모델 진행합니다.\")\n",
    "lstm()\n",
    "print(\"\\nLSTM_2layer 모델 진행합니다.\")\n",
    "lstm_2_layer()\n",
    "print(\"\\nBi-LSTM 모델 진행합니다.\")\n",
    "bidirectional_lstm()\n",
    "print(\"\\nBi-LSTM 2층 모델 진행합니다.\")\n",
    "bidirectional_lstm_2()\n",
    "print(\"\\1D-CNN 모델 진행합니다.\")\n",
    "cnn_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T01:59:46.891027Z",
     "start_time": "2021-04-23T01:59:46.885042Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T01:59:47.146361Z",
     "start_time": "2021-04-23T01:59:47.127411Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T02:11:24.302109Z",
     "start_time": "2021-04-23T02:09:09.912797Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6294 - acc: 0.6471\n",
      "Epoch 00001: val_acc improved from -inf to 0.66934, saving model to best_model.h5\n",
      "14/14 [==============================] - 12s 833ms/step - loss: 0.6294 - acc: 0.6471 - val_loss: 0.6119 - val_acc: 0.6693\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6061 - acc: 0.6540\n",
      "Epoch 00002: val_acc improved from 0.66934 to 0.67506, saving model to best_model.h5\n",
      "14/14 [==============================] - 9s 661ms/step - loss: 0.6061 - acc: 0.6540 - val_loss: 0.5906 - val_acc: 0.6751\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5835 - acc: 0.6883\n",
      "Epoch 00003: val_acc improved from 0.67506 to 0.72654, saving model to best_model.h5\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.5835 - acc: 0.6883 - val_loss: 0.5950 - val_acc: 0.7265\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5517 - acc: 0.7410\n",
      "Epoch 00004: val_acc did not improve from 0.72654\n",
      "14/14 [==============================] - 9s 661ms/step - loss: 0.5517 - acc: 0.7410 - val_loss: 0.5623 - val_acc: 0.7162\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5137 - acc: 0.7748\n",
      "Epoch 00005: val_acc improved from 0.72654 to 0.74600, saving model to best_model.h5\n",
      "14/14 [==============================] - 7s 532ms/step - loss: 0.5137 - acc: 0.7748 - val_loss: 0.5425 - val_acc: 0.7460\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4703 - acc: 0.8071\n",
      "Epoch 00006: val_acc did not improve from 0.74600\n",
      "14/14 [==============================] - 11s 754ms/step - loss: 0.4703 - acc: 0.8071 - val_loss: 0.5632 - val_acc: 0.7254\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4373 - acc: 0.8286\n",
      "Epoch 00007: val_acc improved from 0.74600 to 0.75973, saving model to best_model.h5\n",
      "14/14 [==============================] - 9s 660ms/step - loss: 0.4373 - acc: 0.8286 - val_loss: 0.5048 - val_acc: 0.7597\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3997 - acc: 0.8537\n",
      "Epoch 00008: val_acc improved from 0.75973 to 0.76430, saving model to best_model.h5\n",
      "14/14 [==============================] - 8s 540ms/step - loss: 0.3997 - acc: 0.8537 - val_loss: 0.4988 - val_acc: 0.7643\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3744 - acc: 0.8678\n",
      "Epoch 00009: val_acc improved from 0.76430 to 0.77002, saving model to best_model.h5\n",
      "14/14 [==============================] - 10s 738ms/step - loss: 0.3744 - acc: 0.8678 - val_loss: 0.4843 - val_acc: 0.7700\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3683 - acc: 0.8532\n",
      "Epoch 00010: val_acc did not improve from 0.77002\n",
      "14/14 [==============================] - 9s 636ms/step - loss: 0.3683 - acc: 0.8532 - val_loss: 0.7507 - val_acc: 0.4359\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.5283 - acc: 0.7032\n",
      "Epoch 00011: val_acc did not improve from 0.77002\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 0.5283 - acc: 0.7032 - val_loss: 0.6287 - val_acc: 0.6087\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4531 - acc: 0.8371\n",
      "Epoch 00012: val_acc did not improve from 0.77002\n",
      "14/14 [==============================] - 8s 603ms/step - loss: 0.4531 - acc: 0.8371 - val_loss: 0.5854 - val_acc: 0.7288\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4053 - acc: 0.8892\n",
      "Epoch 00013: val_acc did not improve from 0.77002\n",
      "14/14 [==============================] - 12s 827ms/step - loss: 0.4053 - acc: 0.8892 - val_loss: 0.5524 - val_acc: 0.7574\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T03:29:51.189772Z",
     "start_time": "2021-04-23T03:29:51.178803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델명</th>\n",
       "      <th>test 정확도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>0.642614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.829670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM_2layer</td>\n",
       "      <td>0.640797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.640797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bi-LSTM-2</td>\n",
       "      <td>0.640797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1D-CNN</td>\n",
       "      <td>0.843407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           모델명  test 정확도\n",
       "0          DNN  0.642614\n",
       "1         LSTM  0.829670\n",
       "2  LSTM_2layer  0.640797\n",
       "3      Bi-LSTM  0.640797\n",
       "4    Bi-LSTM-2  0.640797\n",
       "5       1D-CNN  0.843407"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_result,columns=['모델명','test 정확도'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:17:19.280259Z",
     "start_time": "2021-03-31T16:17:15.924231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4627 - acc: 0.8098\n",
      "테스트 정확도: 0.8098\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:18:19.626552Z",
     "start_time": "2021-03-31T16:18:19.607608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  124,   54,    8],\n",
       "       [   0,    0,    0, ...,    0,    0,  394],\n",
       "       [   0,    0,    0, ...,   60,   60,   60],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 3999,  714, 1609],\n",
       "       [   0,    0,    0, ..., 1177,  298,  459],\n",
       "       [   0,    0,    0, ...,    0,  294,  101]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:18:27.302028Z",
     "start_time": "2021-03-31T16:18:25.635484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22834557],\n",
       "       [0.15960008],\n",
       "       [0.05404943],\n",
       "       ...,\n",
       "       [0.43997997],\n",
       "       [0.09528944],\n",
       "       [0.3143381 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = loaded_model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:18:43.744856Z",
     "start_time": "2021-03-31T16:18:43.695961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       933\n",
      "           1       0.81      0.62      0.70       523\n",
      "\n",
      "    accuracy                           0.81      1456\n",
      "   macro avg       0.81      0.77      0.78      1456\n",
      "weighted avg       0.81      0.81      0.80      1456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, np.round(preds,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:19:00.382019Z",
     "start_time": "2021-03-31T16:19:00.329160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8097527472527473\n",
      "Precision:  0.8075\n",
      "Recall:  0.6175908221797323\n",
      "Specificity:  0.917470525187567\n",
      "F1-Score:  0.6998916576381364\n",
      "F2-Score:  0.6480738362760834\n",
      "auc score:  0.7675306736836496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    F2_Score = (5 * Recall * Precision) / (Recall + 4*Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"Specificity: \", Specificity)\n",
    "    print(\"F1-Score: \", F1_Score)\n",
    "    print(\"F2-Score: \", F2_Score)\n",
    "    print(\"auc score: \" , roc_auc_score(label, np.round(predict,0)))\n",
    "model_evaluation(y_test, np.round(preds,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리뷰 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = mecab.morphs(new_sentence) # 토큰화\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "  score = float(loaded_model.predict(pad_new)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 욕설에 가깝습니다.\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 욕설이 아닙니다.\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.09% 확률로 욕설이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('노잼 ..완전 재미 없음 ㅉㅉ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.34% 확률로 욕설에 가깝습니다.\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('병신ㅉㅉ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
